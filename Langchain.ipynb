{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxpewXK4l0D7LLcYWz7crZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahnawaz2506/LLM/blob/main/Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creds- https://learn.deeplearning.ai/langchain-chat-with-your-data/lesson/7/chat Harrison Chase"
      ],
      "metadata": {
        "id": "8WmPvkfrxxvy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUPo7bMKFCHV"
      },
      "outputs": [],
      "source": [
        "! pip install langchain\n",
        "! pip install pypdf\n",
        "!pip install openai\n",
        "!pip install chromadb\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "\n",
        "with open('openai_key.txt', 'r') as file:\n",
        "    # Read the entire content of the file into a string\n",
        "    oikey= file.read()\n",
        "os.environ['OPENAI_API_KEY']=oikey"
      ],
      "metadata": {
        "id": "-KFl8qPaF1pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "sys.path.append('../..')\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "\n",
        "openai.api_key  =oikey"
      ],
      "metadata": {
        "id": "HZB7VLYcFC8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"HP1.pdf\")\n",
        "pages = loader.load()\n",
        "pages[10].metadata"
      ],
      "metadata": {
        "id": "_X9UZ53uFEjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e742dfa7-93a0-4e5b-e7ea-d1bce3323bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'HP1.pdf', 'page': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "persist_directory = 'chroma/'\n",
        "embedding = OpenAIEmbeddings()\n",
        "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
        "print(vectordb._collection.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43zjs7U6GFmO",
        "outputId": "46455467-306b-45fb-a5b4-d2555fc6e48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")\n",
        "splits = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "Z0LHId7vGthK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.dot(embedding1, embedding2)"
      ],
      "metadata": {
        "id": "88nolEoLKPRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")\n",
        "print(vectordb._collection.count())\n"
      ],
      "metadata": {
        "id": "E4_meUojSHGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0a9595-ef05-48d7-b32d-84741f81308a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# docs = vectordb.similarity_search(question,k=3)\n",
        "# vectordb.persist()"
      ],
      "metadata": {
        "id": "XBC4cFs0lrq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# docs[0].page_content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "t5FibGW5mFad",
        "outputId": "1322e198-6358-4b1b-8587-c96569e8f0e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'62 H ARRY  POTTER  \\n \\n not a single witch or wizard who went bad who wasn’t in \\nSlytherin. You-Know-Who was one.’ \\n‘Vol– sorry – You-Know-Who was at Hogwarts?’ ‘Years an’ years ago,’ said Hagrid. They bought Harry’s school books in a shop called Flourish and \\nBlotts where the shelves were stac ked to the ceiling with books as \\nlarge as paving stones bound in leather; books the size of postage stamps in covers of silk; books full of peculiar symbols and a few books with nothing in them at all. Even Dudley , who never read \\nanything, would have been wild to get his hands on some of \\nthese. Hagrid almost had to drag Harry away from Curses and \\nCounter-Curses (Bewitch your Friends and Befuddle your Enemies with the Latest Revenges: Hair Lo ss, Jelly-Legs, T ongue-T ying and \\nmuch, much more)  by Professor Vindictus Viridian. \\n‘I was trying to find out how to curse Dudley .’ \\n‘I’m not sayin’ that’s not a good  idea, but yer not ter use magic \\nin the Muggle world except in very special circumstances,’ said Hagrid. ‘An’ anyway , yeh couldn’ work any of them curses yet, yeh’ll need a lot more study before yeh get ter that level.’ \\nHagrid wouldn’t let Harry buy a solid gold cauldron, either (‘It \\nsays pewter on yer list’), but they got a nice set of scales for \\nweighing potion ingredients and a collapsible brass telescope.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QA\n"
      ],
      "metadata": {
        "id": "E8YG4b8SwFBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "llm_name = \"gpt-3.5-turbo\"\n",
        "llm = ChatOpenAI(model_name=llm_name, temperature=0)\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,chain_type=\"stuff\",\n",
        "    retriever=vectordb.as_retriever(),return_source_documents=True\n",
        "    ,chain_type_kwargs=chain_type_kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "BNfu9G2qmL72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Give me a summary of harry potter book in 3 lines\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "bhTg6oOvqH9-",
        "outputId": "89108a3c-f731-4651-ccee-f28aeecf2ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Harry Potter, an ordinary boy, discovers he is a wizard and his parents were killed by a Dark Lord. He attends Hogwarts School of Witchcraft and Wizardry, where he embarks on a dangerous adventure to find a missing stone with incredible powers. The book is filled with magic, mystery, and the beginning of Harry\\'s journey as the famous \"boy who lived.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "p_temp=\"\"\"Use follwing picess of context to answer the question at the end. If it is not present in the context say you dont know\n",
        "{context}\n",
        "Question:{question}\n",
        "\"\"\"\n",
        "Prompt=PromptTemplate(template=p_temp,input_variables=[\"context\",\"question\"])\n",
        "chain_type_kwargs={\"prompt\":Prompt}"
      ],
      "metadata": {
        "id": "6qFWKe8hqM6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chat"
      ],
      "metadata": {
        "id": "TMUzDU0RwJWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True\n",
        ")\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "retriever=vectordb.as_retriever()\n",
        "qa = ConversationalRetrievalChain.from_llm(\n",
        "    llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "5k3glbedqdqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"where did harry potter live?\"\n",
        "result = qa({\"question\": question})\n",
        "result[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PQJpD0f1wN-e",
        "outputId": "9ef7d23d-511f-4b41-c426-2a4d21bb233c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Harry Potter lived with his aunt, uncle, and cousin in a house on Privet Drive in the town of Little Whinging, Surrey, England.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"was he a boy or a girl ?\"\n",
        "result = qa({\"question\": question})\n",
        "result[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KDvy7sBNwe_o",
        "outputId": "7ac645e2-ac9d-48a1-cbea-c7409e4cd310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Harry Potter is a boy.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create chatbot\n"
      ],
      "metadata": {
        "id": "S-8WeheixjnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import DocArrayInMemorySearch\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.chains import RetrievalQA,  ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "uAFOAGS5wy9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_db(file, chain_type, k):\n",
        "    # load documents\n",
        "    loader = PyPDFLoader(file)\n",
        "    documents = loader.load()\n",
        "    # split documents\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "    # define embedding\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    # create vector database from data\n",
        "    db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
        "    # define retriever\n",
        "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
        "    # create a chatbot chain. Memory is managed externally.\n",
        "    qa = ConversationalRetrievalChain.from_llm(\n",
        "        llm=ChatOpenAI(model_name=llm_name, temperature=0),\n",
        "        chain_type=chain_type,\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True,\n",
        "        return_generated_question=True,\n",
        "    )\n",
        "    return qa\n"
      ],
      "metadata": {
        "id": "WGviodjFxnKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import panel as pn\n",
        "import param\n",
        "\n",
        "class cbfs(param.Parameterized):\n",
        "    chat_history = param.List([])\n",
        "    answer = param.String(\"\")\n",
        "    db_query  = param.String(\"\")\n",
        "    db_response = param.List([])\n",
        "\n",
        "    def __init__(self,  **params):\n",
        "        super(cbfs, self).__init__( **params)\n",
        "        self.panels = []\n",
        "        self.loaded_file = \"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"\n",
        "        self.qa = load_db(self.loaded_file,\"stuff\", 4)\n",
        "\n",
        "    def call_load_db(self, count):\n",
        "        if count == 0 or file_input.value is None:  # init or no file specified :\n",
        "            return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
        "        else:\n",
        "            file_input.save(\"temp.pdf\")  # local copy\n",
        "            self.loaded_file = file_input.filename\n",
        "            button_load.button_style=\"outline\"\n",
        "            self.qa = load_db(\"temp.pdf\", \"stuff\", 4)\n",
        "            button_load.button_style=\"solid\"\n",
        "        self.clr_history()\n",
        "        return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
        "\n",
        "    def convchain(self, query):\n",
        "        if not query:\n",
        "            return pn.WidgetBox(pn.Row('User:', pn.pane.Markdown(\"\", width=600)), scroll=True)\n",
        "        result = self.qa({\"question\": query, \"chat_history\": self.chat_history})\n",
        "        self.chat_history.extend([(query, result[\"answer\"])])\n",
        "        self.db_query = result[\"generated_question\"]\n",
        "        self.db_response = result[\"source_documents\"]\n",
        "        self.answer = result['answer']\n",
        "        self.panels.extend([\n",
        "            pn.Row('User:', pn.pane.Markdown(query, width=600)),\n",
        "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=600, style={'background-color': '#F6F6F6'}))\n",
        "        ])\n",
        "        inp.value = ''  #clears loading indicator when cleared\n",
        "        return pn.WidgetBox(*self.panels,scroll=True)\n",
        "\n",
        "    @param.depends('db_query ', )\n",
        "    def get_lquest(self):\n",
        "        if not self.db_query :\n",
        "            return pn.Column(\n",
        "                pn.Row(pn.pane.Markdown(f\"Last question to DB:\", styles={'background-color': '#F6F6F6'})),\n",
        "                pn.Row(pn.pane.Str(\"no DB accesses so far\"))\n",
        "            )\n",
        "        return pn.Column(\n",
        "            pn.Row(pn.pane.Markdown(f\"DB query:\", styles={'background-color': '#F6F6F6'})),\n",
        "            pn.pane.Str(self.db_query )\n",
        "        )\n",
        "\n",
        "    @param.depends('db_response', )\n",
        "    def get_sources(self):\n",
        "        if not self.db_response:\n",
        "            return\n",
        "        rlist=[pn.Row(pn.pane.Markdown(f\"Result of DB lookup:\", styles={'background-color': '#F6F6F6'}))]\n",
        "        for doc in self.db_response:\n",
        "            rlist.append(pn.Row(pn.pane.Str(doc)))\n",
        "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
        "\n",
        "    @param.depends('convchain', 'clr_history')\n",
        "    def get_chats(self):\n",
        "        if not self.chat_history:\n",
        "            return pn.WidgetBox(pn.Row(pn.pane.Str(\"No History Yet\")), width=600, scroll=True)\n",
        "        rlist=[pn.Row(pn.pane.Markdown(f\"Current Chat History variable\", styles={'background-color': '#F6F6F6'}))]\n",
        "        for exchange in self.chat_history:\n",
        "            rlist.append(pn.Row(pn.pane.Str(exchange)))\n",
        "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
        "\n",
        "    def clr_history(self,count=0):\n",
        "        self.chat_history = []\n",
        "        return\n"
      ],
      "metadata": {
        "id": "Eiw_YXs8xo1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cb = cbfs()\n",
        "\n",
        "file_input = pn.widgets.FileInput(accept='.pdf')\n",
        "button_load = pn.widgets.Button(name=\"Load DB\", button_type='primary')\n",
        "button_clearhistory = pn.widgets.Button(name=\"Clear History\", button_type='warning')\n",
        "button_clearhistory.on_click(cb.clr_history)\n",
        "inp = pn.widgets.TextInput( placeholder='Enter text here…')\n",
        "\n",
        "bound_button_load = pn.bind(cb.call_load_db, button_load.param.clicks)\n",
        "conversation = pn.bind(cb.convchain, inp)\n",
        "\n",
        "jpg_pane = pn.pane.Image( './img/convchain.jpg')\n",
        "\n",
        "tab1 = pn.Column(\n",
        "    pn.Row(inp),\n",
        "    pn.layout.Divider(),\n",
        "    pn.panel(conversation,  loading_indicator=True, height=300),\n",
        "    pn.layout.Divider(),\n",
        ")\n",
        "tab2= pn.Column(\n",
        "    pn.panel(cb.get_lquest),\n",
        "    pn.layout.Divider(),\n",
        "    pn.panel(cb.get_sources ),\n",
        ")\n",
        "tab3= pn.Column(\n",
        "    pn.panel(cb.get_chats),\n",
        "    pn.layout.Divider(),\n",
        ")\n",
        "tab4=pn.Column(\n",
        "    pn.Row( file_input, button_load, bound_button_load),\n",
        "    pn.Row( button_clearhistory, pn.pane.Markdown(\"Clears chat history. Can use to start a new topic\" )),\n",
        "    pn.layout.Divider(),\n",
        "    pn.Row(jpg_pane.clone(width=400))\n",
        ")\n",
        "dashboard = pn.Column(\n",
        "    pn.Row(pn.pane.Markdown('# ChatWithYourData_Bot')),\n",
        "    pn.Tabs(('Conversation', tab1), ('Database', tab2), ('Chat History', tab3),('Configure', tab4))\n",
        ")\n",
        "dashboard"
      ],
      "metadata": {
        "id": "2_rdNhLMxpp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TreeNode:\n",
        "    def __init__(self, val):\n",
        "        self.val = val\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "\n",
        "def sorted_list_to_bst(nums):\n",
        "    if not nums:\n",
        "        return None\n",
        "\n",
        "    # Find the middle element\n",
        "    mid = len(nums) // 2\n",
        "\n",
        "    # Create the root node\n",
        "    root = TreeNode(nums[mid])\n",
        "\n",
        "    # Recursively build the left and right subtrees\n",
        "    root.left = sorted_list_to_bst(nums[:mid])\n",
        "    root.right = sorted_list_to_bst(nums[mid+1:])\n",
        "\n",
        "    return root\n",
        "\n",
        "def inorder_traversal(root):\n",
        "    if root:\n",
        "        inorder_traversal(root.left)\n",
        "        print(root.val, end=' ')\n",
        "        inorder_traversal(root.right)\n",
        "\n",
        "# Example usage:\n",
        "sorted_list = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "bst_root = sorted_list_to_bst(sorted_list)\n",
        "\n",
        "# Print the inorder traversal of the resulting BST\n",
        "inorder_traversal(bst_root)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wouFZNrzvy4h",
        "outputId": "23ea25b5-c971-4c8d-cb80-f70270e4507f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 2 3 4 5 6 7 8 9 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ASzDn0OSvze-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}